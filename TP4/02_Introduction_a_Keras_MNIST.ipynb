{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "TP1_Some_basics_about_learning_process.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/CHPS0704/blob/main/TP4/02_Introduction_a_Keras_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construire un mod√®le de r√©seaux de neurones avec Keras\n",
        "\n",
        "Keras est une biblioth√®que \"haut niveau\" utilis√©e pour simplifier la description de mod√®les de r√©seaux de neurones sur Tensorflow (biblioth√®que IA de Google). L'avantage surtout est de pouvoir utiliser des GPU pour acc√©l√©rer le calcul.\n",
        "\n",
        "Le travail avec Keras suit un cheminement similaires √† celui avec Scikit-Learn, mais il y a quelques diff√©rences √† retenir."
      ],
      "metadata": {
        "id": "EpQRZSswWmWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras\n",
        "\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import numpy as np\n",
        "print (tf.__version__)\n",
        "print(keras.__version__)\n"
      ],
      "metadata": {
        "id": "nO3TA6f7WmWJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le paragraphe suivant vous avez certainement eu un message d'erreur indiquant que vous n'avez pas des GPU. Dans ce cas, Keras utilisera la CPU de la machine.\n",
        "\n",
        "## Chargement de donn√©es\n",
        "\n",
        "Tout comme Scikit-Learn, Keras a aussi un ensemble de datasets pr√™t √† utilisation pour des exemples. Dans le cas suivant, nous allons charger le dataset MNIST (√©criture √† la main) et le s√©parer en deux groupes : Train et Test. Les donn√©es de validation (v√©rification pendant l'entra√Ænement) seront s√©par√©s du groupe Train plus tard."
      ],
      "metadata": {
        "id": "5eYo87D2WmWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "q2eLH6ACWmWJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape\n",
        "x_test.shape\n",
        "y_test.shape"
      ],
      "metadata": {
        "id": "odgDUCJSWmWJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "iOXq4OkDWmWK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les donn√©es de MNIST se pr√©sentent sous la forme d'images 28x28 pixels, avec 256 tons de gris. Les labels (`y_train`, par exemple) correspondent aux caract√®res repr√©sent√©s : les chiffres 0 √† 9.\n",
        "\n",
        "Le paragraphe suivant d√©finit une fonction permettant de visualiser ce dataset."
      ],
      "metadata": {
        "id": "8cNaXhPsWmWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(x,y=None, indices='all', columns=12, x_size=1, y_size=1,\n",
        "                colorbar=False, y_pred=None, cm='binary', norm=None, y_padding=0.35, spines_alpha=1,\n",
        "                fontsize=20, interpolation='lanczos', save_as='auto'):\n",
        "    \"\"\"\n",
        "    Show some images in a grid, with legends\n",
        "    args:\n",
        "        x             : images - Shapes must be (-1,lx,ly) (-1,lx,ly,1) or (-1,lx,ly,3),(-1,1,lx,ly) or (-1,3,lx,ly)\n",
        "        y             : real classes or labels or None (None)\n",
        "        indices       : indices of images to show or 'all' for all ('all')\n",
        "        columns       : number of columns (12)\n",
        "        x_size,y_size : figure size (1), (1)\n",
        "        colorbar      : show colorbar (False)\n",
        "        y_pred        : predicted classes (None)\n",
        "        cm            : Matplotlib color map (binary)\n",
        "        norm          : Matplotlib imshow normalization (None)\n",
        "        y_padding     : Padding / rows (0.35)\n",
        "        spines_alpha  : Spines alpha (1.)\n",
        "        font_size     : Font size in px (20)\n",
        "        save_as       : Filename to use if save figs is enable ('auto')\n",
        "    returns:\n",
        "        nothing\n",
        "    \"\"\"\n",
        "    if indices=='all': indices=range(len(x))\n",
        "    if norm and len(norm) == 2: norm = matplotlib.colors.Normalize(vmin=norm[0], vmax=norm[1])\n",
        "    draw_labels = (y is not None)\n",
        "    draw_pred   = (y_pred is not None)\n",
        "    # Torch Tensor ?\n",
        "    if y.__class__.__name__      == 'Tensor': y=y.numpy()\n",
        "    if y_pred.__class__.__name__ == 'Tensor': y_pred=y_pred.detach().numpy()\n",
        "\n",
        "    rows        = math.ceil(len(indices)/columns)\n",
        "    fig=plt.figure(figsize=(columns*x_size, rows*(y_size+y_padding)))\n",
        "    n=1\n",
        "    for i in indices:\n",
        "        axs=fig.add_subplot(rows, columns, n)\n",
        "        n+=1\n",
        "        # ---- Shape is (lx,ly)\n",
        "        if len(x[i].shape)==2:\n",
        "            xx=x[i]\n",
        "        # ---- Shape is (lx,ly,c) or (c,lx,ly)\n",
        "        if len(x[i].shape)==3:\n",
        "            if x[i].__class__.__name__ == 'Tensor':\n",
        "               (c,lx,ly)=x[i].shape\n",
        "               if c==1:\n",
        "                   xx=x[i].permute(1,2,0).numpy().reshape(lx,ly)\n",
        "               else:\n",
        "                   xx=x[i].permute(1,2,0).numpy() #---> (lx,ly,n)\n",
        "            else:\n",
        "                (lx,ly,c)=x[i].shape\n",
        "                if c==1:\n",
        "                    xx=x[i].reshape(lx,ly)\n",
        "                else:\n",
        "                    xx=x[i]\n",
        "\n",
        "        img=axs.imshow(xx,   cmap = cm, norm=norm, interpolation=interpolation)\n",
        "        axs.spines['right'].set_visible(True)\n",
        "        axs.spines['left'].set_visible(True)\n",
        "        axs.spines['top'].set_visible(True)\n",
        "        axs.spines['bottom'].set_visible(True)\n",
        "        axs.spines['right'].set_alpha(spines_alpha)\n",
        "        axs.spines['left'].set_alpha(spines_alpha)\n",
        "        axs.spines['top'].set_alpha(spines_alpha)\n",
        "        axs.spines['bottom'].set_alpha(spines_alpha)\n",
        "        axs.set_yticks([])\n",
        "        axs.set_xticks([])\n",
        "        if draw_labels and not draw_pred:\n",
        "            axs.set_xlabel(y[i],fontsize=fontsize)\n",
        "        if draw_labels and draw_pred:\n",
        "            if y[i]!=y_pred[i]:\n",
        "                axs.set_xlabel(f'{y_pred[i]} ({y[i]})',fontsize=fontsize)\n",
        "                axs.xaxis.label.set_color('red')\n",
        "            else:\n",
        "                axs.set_xlabel(y[i],fontsize=fontsize)\n",
        "        if colorbar:\n",
        "            fig.colorbar(img,orientation=\"vertical\", shrink=0.65)\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "DlffLJa0u_Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons donc afficher l'un des caract√®res du groupe Train (celui √† la position 27) mais aussi tout la plage entre les donn√©es 5 et 41. Remarquez le \"label\" correspondant sous chaque image."
      ],
      "metadata": {
        "id": "AW52c1d3O5T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[27])\n",
        "plot_images(x_train, y_train, indices=[27],  x_size=5,y_size=5, colorbar=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "rsjX4ZScO5T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(x_train, y_train, range(5,41), columns=12)"
      ],
      "metadata": {
        "id": "6UZASiFq7Nfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1 - Normalisation des donn√©es**\n",
        "\n",
        "Les valeurs de base son des entiers entre 0 et 255 pour repr√©senter les 256 tons de gris. La majorit√© des algorithmes utilisent des valeurs r√©els, de pr√©f√©rence dans la fourchette 0 √† 1 ou -1 √† 1.\n",
        "\n",
        "Les paragraphes suivantes modifient le type des donn√©es (`float32`) puis font une normalisation simple (diviser la valeur par `max`, qui dans ce cas do√Æt √™tre de 255). Bien s√ªr, d'autres m√©thodes de normalisation plus √©labor√©es sont possibles, mais √ßa suffit pour l'instant."
      ],
      "metadata": {
        "id": "pSIUUpzqO5UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "metadata": {
        "trusted": true,
        "id": "RQp1Q6ADO5UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before normalization : Min={}, max={}'.format(x_train.min(),x_train.max()))\n",
        "\n",
        "xmax=x_train.max()\n",
        "x_train = x_train / xmax\n",
        "x_test  = x_test  / xmax\n",
        "\n",
        "print('After normalization  : Min={}, max={}'.format(x_train.min(),x_train.max()))"
      ],
      "metadata": {
        "trusted": true,
        "id": "6QWNy_ePO5UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 - Transformer les donn√©es cat√©goriques**\n",
        "Lorsqu'on a des donn√©es cat√©goriques (texte ou num√©ros), il faut les transformer afin d'√©viter des mauvaises compr√©hensions de la part de l'algorithme (par exemple, supposer que une classe 2 vient toujours apr√®s une classe 1). Dans notre cas, nous allons transformer les classes 0 √† 9 en repr√©sentations num√©riques (similaire √† HotOneEncoder de Sklearn), afin de rendre ind√©pendantes ces classes."
      ],
      "metadata": {
        "id": "qz-IyPVqO5UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_hotone = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test_hotone = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AgI0qRWrO5UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_hotone"
      ],
      "metadata": {
        "id": "5RGjh84XWmWK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## La Cr√©ation d'un mod√®le\n",
        "\n",
        "Keras a plusieurs modes permettant la cr√©ation de mod√®les de r√©seaux de neurones. Dans ce cas, nous allons utiliser l'API `Sequential` qui permet de d√©crire couche par couche du r√©seau et les empiler (gr√¢ce √† `add()`).\n",
        "\n",
        "Nous allons faire un mod√®le simple avec des r√©seaux denses (totalement connect√©s). La premi√®re couche d√©finit la taille de l'entr√©e (les 784 valeurs re√ßus du dataset), les autres utilisent par d√©faut la taille de la sortie de la couche pr√©c√©dente. Egalement, nous indiquons que chaque couche comptera avec 10 neurones.\n",
        "\n",
        "Finalemen, remarquez qu'on utilise deux types de fonction d'activation, sigmoid et softmax.\n",
        "Pour simplifier la description, sigmoid donne une probabilit√© entre 0 et 1, alors que Softmax affiche \"1\" sur la sortie avec la plus grande probabilit√© et \"0\" sur les autres. C'est pour cela qu'on utilise Softmax √† la sortie, √ßa permet d'avoir un r√©sultat plut√¥t qu'une liste de probabilit√©s."
      ],
      "metadata": {
        "id": "hXtTapcTO5UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "# Declaration du mod√®le en Keras\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Input((28,28)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(30, activation='sigmoid'))\n",
        "model.add(layers.Dense(20, activation='sigmoid'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# r√©sum√© du mod√®le\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "U9XLxq-BWmWK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entra√Ænement du mod√®le\n",
        "\n",
        "Une fois d√©fini le mod√®le, il faut l'entra√Æner avec les donn√©es.\n",
        "Le paragraphe suivant d√©finit les hyperparam√®tres du mod√®le, dont le `batch_size`(taille des sous-ensembles utilis√©s dans la descente de gradient), le nombre d'epochs (parcours de l'ensemble de donn√©es d'entra√Ænement).\n",
        "\n",
        "L'appel √† compile g√©n√®re le graphe d'ex√©cution (un r√©seau de neurones = un graphe) et indique aussi qu'on utilise le mod√®le de descente de gradient SGD, que la m√©trique utilis√©e est l'accuracy (m√©trique qui correspond √† (TP+TN)/(TP+TN+FP+FN)), et que la fonction de perte est la `categorical_crossentropy`, une fonction qui compare les probabilit√©s pour des labels cat√©goriques."
      ],
      "metadata": {
        "id": "pg4Axb4GO5UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "#num_classes = 10\n",
        "epochs= 20\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  optimizer='SGD',  metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "32wR8ClWWmWL",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalement, on lance l'entra√Ænement. Remarquez aussi qu'on n'a pas cr√©e des donn√©es Validation avant, on le fera **sur place** en r√©servant 10% des donn√©es de Train (appel √† `validation_split=0.1`).\n",
        "\n",
        "Comme le dataset est simple, on peut faire l'entra√Ænement m√™me sans un GPU."
      ],
      "metadata": {
        "id": "1A-EfnLBO5UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train_hotone, batch_size=batch_size, epochs=epochs, validation_split=0.1,verbose=1 )\n",
        "\n",
        "#verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
        "# Je vous invite √† lire la documentation : https://keras.io/models/sequential/"
      ],
      "metadata": {
        "id": "Jng3P9z1WmWL",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les paragraphes suivants nous permettent de voir comment le mod√®le am√©liore sa performance au fil des epochs"
      ],
      "metadata": {
        "id": "Y-bcqc4zO5UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, figsize=(8,6),\n",
        "                 plot={\"Accuracy\":['accuracy','val_accuracy'], 'Loss':['loss', 'val_loss']}):\n",
        "    \"\"\"\n",
        "    Show history\n",
        "    args:\n",
        "        history: history\n",
        "        figsize: fig size\n",
        "        plot: list of data to plot : {<title>:[<metrics>,...], ...}\n",
        "    \"\"\"\n",
        "    fig_id=0\n",
        "    for title,curves in plot.items():\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.title(title)\n",
        "        plt.ylabel(title)\n",
        "        plt.xlabel('Epoch')\n",
        "        for c in curves:\n",
        "            plt.plot(history.history[c])\n",
        "        plt.legend(curves, loc='upper left')\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "mrjA4FOuO5UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history, figsize=(6,4))"
      ],
      "metadata": {
        "trusted": true,
        "id": "QKhT0-sOO5UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, on peut estimer la performance du mod√®le avec les donn√©es Test.\n",
        "\n",
        "Comparez ces valeur avec ceux de l'entra√Ænement (`val_loss` et `val_accuracy`\n",
        " ci-dessus)."
      ],
      "metadata": {
        "id": "TGLQHMDPO5UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test_hotone,verbose=0)\n",
        "\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "qTbNPwg6WmWL",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ces r√©sultats montrent que, √©tonemment, le mod√®le se porte mieux avec le groupe de validation (val_accuracy), c'est int√©ressant üëç."
      ],
      "metadata": {
        "id": "zMgRWzJsO5UC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmZYQe-HzKYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quelques erreurs\n",
        "\n",
        "Si vous avez fait attention, on n'a toujours pas touch√© le dataset `x_test/y_test`, vu qu'on a fait l'entra√Ænement avec 90% et valid√© avec 10% du x_train.\n",
        "\n",
        "On peut donc utiliser x_test comme \"nouvelle donn√©e\" et v√©rifier si notre mod√®le rend bien les r√©ponses.\n",
        "\n",
        "Dans le prochain paragraph, nous allons donc produire une estimation `y_pred` √† partir de `x_test`. Comme la sortie du mod√®le est un array de 10 positions (notre `y_train_hotone`), on passe ce r√©sultat √† `np.argmax()` pour obtenir juste le num√©ro de la classe."
      ],
      "metadata": {
        "id": "RoHS31T-ySZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# d'abord, on utilise le mod√®le pour faire une pr√©vision sur l'ensemble de test\n",
        "# √áa retourne une liste avec 10 colonnes (une par sortie possible).\n",
        "y_pred_hotone = model.predict(x_test)\n",
        "\n",
        "# avec la fonction argmax, on ne garde que l'index de la colonne avec la plus grande valeur\n",
        "y_pred    = np.argmax(y_pred_hotone, axis=-1)"
      ],
      "metadata": {
        "id": "94ywQWlvzOoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant, on affiche quelques √©l√©ments, avec la valeur pr√©dite et la valeur attendue (entre parenth√®ses). Vous pouvez v√©rifier que quelques pr√©dictions sont incorrectes."
      ],
      "metadata": {
        "id": "F661igG7zV6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plot_images(x_test, y_test, range(0,200), columns=12, x_size=1, y_size=1, y_pred=y_pred)"
      ],
      "metadata": {
        "id": "u_TTk0YGWmWL",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice :\n",
        "Avec ce mod√®le basique, on a obtenu un taux d'accuracy d'environ 80%.\n",
        "- Essayer d'am√©liorer la performence du mod√®le, en modifiant les fonctions d'activation, ou/et en n ajoutant le nombre de neurones et des couches interm√©diaires.\n",
        "\n"
      ],
      "metadata": {
        "id": "0G4jaLW6WmWL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbsfpaiazW2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus : Quelques exemples de fonctions d'activation de base\n",
        "\n"
      ],
      "metadata": {
        "id": "8_w-7ZF9WmWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation functions"
      ],
      "metadata": {
        "id": "Kd01IKzdWmWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "x = np.arange(-6, 6, 0.1)"
      ],
      "metadata": {
        "id": "ShyJUe2VWmWE",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear  :  Fonction d'activation lin√©aire\n",
        "\n",
        "C'est une fonction simple de la forme: f(x) = ax ou f(x) = x. En gros, l'entr√©e passe √† la sortie sans une tr√®s grande modification ou alors sans aucune modification."
      ],
      "metadata": {
        "id": "K_RTo7D7WmWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear(x):\n",
        "    a = []\n",
        "    for item in x:\n",
        "        a.append(item)\n",
        "    return a\n",
        "\n",
        "y = linear(x)\n",
        "\n",
        "plt.plot(x,y)\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yoxBCvBSWmWF",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sigmoid\n",
        "\n",
        "En math√©matiques, la fonction sigmo√Øde (dite aussi courbe en S) est d√©finie par :\n",
        "\n",
        "$$ f(x)=\\frac{1}{1 + e^{- x}}$$ pour tout r√©el x ;\n",
        "\n",
        "\n",
        "Le but premier de la fonction est de r√©duire la valeur d'entr√©e pour la r√©duire entre 0 et 1. En plus d'exprimer la valeur sous forme de probabilit√©, si la valeur en entr√©e est un tr√®s grand nombre positif, la fonction convertira cette valeur en une probabilit√© de 1. A l'inverse, si la valeur en entr√©e est un tr√®s grand nombre n√©gatif, la fonction convertira cette valeur en une probabilit√© de 0. D'autre part, l'√©quation de la courbe est telle que, seules les petites valeurs influent r√©ellement sur la variation des valeurs en sortie.\n",
        "\n",
        "La fonction Sigmo√Øde a plusieurs d√©faults:\n",
        "\n",
        "- Elle n'est pas centr√©e sur z√©ro, c'est √† dire que des entr√©es n√©gatives peuvent engendrer des sorties positives.\n",
        "\n",
        "- Etant assez plate, elle influe assez faiblement sur les neurones par rapport √† d'autres fonctions d'activations. Le r√©sultat est souvent tr√®s proche de 0 ou de 1 causant la saturation de certains neurones.\n",
        "\n",
        "- Elle est couteuse en terme de calcul car elle comprend la fonction exponentielle.\n"
      ],
      "metadata": {
        "id": "hd_1He_kWmWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    a = []\n",
        "    for item in x:\n",
        "        a.append(1/( (1+math.exp(-item) * 1)))\n",
        "        # ici j'ai pri A = 1 : plus A est grand plus on se rapproche √† la fonction echelon ...\n",
        "\n",
        "    return a\n",
        "\n",
        "y = sigmoid(x)\n",
        "\n",
        "plt.plot(x,y)\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "scrolled": true,
        "id": "XiQyZuPMWmWG",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tahn :  Tangente Hyperbolique\n",
        "\n",
        "Cette fonction ressemble √† la fonction Sigmo√Øde. La diff√©rence avec la fonction Sigmo√Øde est que la fonction Tanh produit un r√©sultat compris entre -1 et 1. La fonction Tanh est en terme g√©n√©ral pr√©f√©rable √† la fonction Sigmo√Øde car elle est centr√©e sur z√©ro. Les grandes entr√©es n√©gatives tendent vers -1 et les grandes entr√©es positives tendent vers 1.\n",
        "\n",
        "Mis √† part cet avantage, la fonction Tanh poss√®de les m√™mes autres inconv√©nients que la fonction Sigmo√Øde."
      ],
      "metadata": {
        "id": "N6pM0PdtWmWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh(x, derivative=False):\n",
        "    if (derivative == True):\n",
        "        return (1 - (x ** 2))\n",
        "    return np.tanh(x)\n",
        "\n",
        "\n",
        "y = tanh(x)\n",
        "\n",
        "plt.plot(x,y)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lL-Po6KzWmWH",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ReLU : Unit√© de Rectification Lin√©aire\n",
        "Pour r√©soudre le probl√®me de saturation des deux fonctions pr√©c√©dentes (Sigmo√Øde et Tanh) il existe la fonction ReLU (Unit√© de Rectification Lin√©aire). Cette fonction est la plus utilis√©e.\n",
        "\n",
        "La fonction ReLU est intepr√©t√©e par la formule: f(x) = max(0, x). Si l'entr√©e est n√©gative la sortie est 0 et si elle est positive, alors la sortie est √©gale √† x. Cette fonction d'activation augmente consid√©rablement la convergence du r√©seau et ne sature pas.\n",
        "\n",
        "Mais la fonction ReLU n'est pas parfaite. Si la valeur d'entr√©e est n√©gative, le neurone reste inactif, ainsi les poids ne sont pas mis √† jour et le r√©seau n‚Äôapprend pas."
      ],
      "metadata": {
        "id": "Su5qkZlWWmWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    a = []\n",
        "    for item in x:\n",
        "        if item > 0:\n",
        "            a.append(item)\n",
        "        else:\n",
        "            a.append(0)\n",
        "    return a\n",
        "\n",
        "\n",
        "y = relu(x)\n",
        "\n",
        "plt.plot(x,y)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NaHM-WDRWmWI",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_77OUTHIO5UQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}