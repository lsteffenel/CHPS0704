{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/CHPS0704/blob/main/TP3/5_DBSCAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3fe437b",
      "metadata": {
        "id": "d3fe437b"
      },
      "source": [
        "\n",
        "<a id='chap-tpdbscan'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "302d5aa0",
      "metadata": {
        "id": "302d5aa0"
      },
      "source": [
        "# Travaux pratiques - DBSCAN\n",
        "\n",
        "\n",
        "\n",
        "Références externes utiles :\n",
        "\n",
        "> - [Documentation NumPy](https://docs.scipy.org/doc/numpy/user/index.html)  \n",
        "- [Documentation SciPy](https://docs.scipy.org/doc/scipy/reference/)  \n",
        "- [Documentation MatPlotLib](http://matplotlib.org/)  \n",
        "- [Site scikit-learn](http://scikit-learn.org/stable/index.html)  \n",
        "- [Site langage python](https://www.python.org)  \n",
        "\n",
        "\n",
        "\n",
        "L’objectif de cette séance de TP est d’illustrer la mise en pratique de\n",
        "la classification automatique avec DBSCAN. Dans un premier temps, nous\n",
        "observerons le comportement de l’algorithme dans un cas synthétique\n",
        "mettant en échec *k-means*. Nous verrons comment utiliser les\n",
        "heuristiques classiques pour déterminer les paramètres de l’algorithme\n",
        "et comment interpréter le partitionnement obtenu. Enfin, nous\n",
        "appliquerons DBSCAN sur un jeu de données réelles et nous illustrerons\n",
        "son usage pour la détection de données aberrantes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ed29a59",
      "metadata": {
        "id": "4ed29a59"
      },
      "source": [
        "## La classification par densité dans scikit-learn\n",
        "\n",
        "Comme nous l’avons vu dans le TP précédent, scikit-learn propose de\n",
        "nombreuses [méthodes de classification\n",
        "automatique](http://scikit-learn.org/stable/modules/clustering.html).\n",
        "Nous nous intéressons pour cette séance à **DBSCAN** (*Density-Based\n",
        "Spatial Clustering of Applications with Noise*).\n",
        "\n",
        "Comme *k-means*, DBSCAN permet d’obtenir pour une matrice d’observation\n",
        "`n_samples x n_features` un vecteur correspondant aux `n_samples`\n",
        "numéros des groupes (*cluster*) pour ces observations. En revanche,\n",
        "DBSCAN est une méthode transductive : l’algorithme ne permet pas de\n",
        "produire des classifications pour de nouvelles données (il est\n",
        "nécessaire de réentraîner le modèle en incluant les nouvelles\n",
        "observations).\n",
        "\n",
        "La description de l’implémentation de DBSCAN se trouve dans\n",
        "[https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a40aef8",
      "metadata": {
        "id": "2a40aef8"
      },
      "source": [
        "## Classification avec DBSCAN de données générées\n",
        "\n",
        "Commençons par générer un jeu de données de 500 observations dans un\n",
        "espace 2D. Nous allons utiliser une fonction intégrée à scikit-learn\n",
        "permettant de produire des nuages de points circulaires\n",
        "([make_circles](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45c22584",
      "metadata": {
        "hide-output": false,
        "id": "45c22584"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Générons un nuage de points composé de deux cercles\n",
        "# Le nuage contient 500 observations (`n_samples`) bruitées par\n",
        "# un bruit gaussien d'écart-type 0.1 (`noise`).\n",
        "# Le rapport entre le rayon du petit cercle et du grand cercle\n",
        "# est de 0.3 (`factor`).\n",
        "data, labels = sklearn.datasets.make_circles(n_samples=500, noise=0.1, factor=0.3, random_state=0)\n",
        "\n",
        "print(data.shape)\n",
        "# Permutation aléatatoire des lignes de la matrice (on mélange les observations)\n",
        "data, labels = shuffle(data, labels)\n",
        "\n",
        "# Affichage du nuage de points\n",
        "plt.scatter(data[:,0], data[:,1], c=labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "708f9eb4",
      "metadata": {
        "id": "708f9eb4"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Combien de groupes comporte ce jeu de données ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37ffe265",
      "metadata": {
        "id": "37ffe265"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Réaliser un partitionnement de ce jeu de données à l’aide de $ k $-means. À quoi peut-on s’attendre ? Que constatez-vous ?\n",
        "\n",
        "Les deux cercles étant séparés par une zone sans données, une méthode\n",
        "basée sur la densité semble appropriée. Nous pouvons créer un modèle de\n",
        "*clustering* utilisant DBSCAN en l’important depuis scikit-learn :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c3c93c6",
      "metadata": {
        "hide-output": false,
        "id": "5c3c93c6"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "db = DBSCAN()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b6a3cc",
      "metadata": {
        "id": "b6b6a3cc"
      },
      "source": [
        "Les arguments du constructeur de DBSCAN sont les suivants :\n",
        "\n",
        "- `eps`: la dimension du voisinage, c’est-à-dire la distance maximale\n",
        "  entre deux observations permettant de les considérer comme voisines\n",
        "  l’une de l’autre,  \n",
        "- `min_samples`: le nombre minimal de voisins que doit avoir un point\n",
        "  central,  \n",
        "- `metric`: la distance à considérer (par défaut, la distance\n",
        "  Euclidienne est utilisée).  \n",
        "\n",
        "\n",
        "Il est possible d’appeler les méthodes suivantes :\n",
        "\n",
        "- `.fit(X)`: réalise une classification automatique en utilisant la\n",
        "  méthode DBSCAN sur la matrice d’observations `X`. Les résultats\n",
        "  sont stockés dans l’attribut `.labels_`.  \n",
        "- `.fit_predict(X)`: identique à `.fit(X)` mais renvoie directement\n",
        "  les étiquettes des groupes.  \n",
        "\n",
        "\n",
        "Les attributs suivants sont disponibles après l’appel à la méthode\n",
        "`.fit()`:\n",
        "\n",
        "- `core_sample_indices_`: les indices des points centraux.  \n",
        "- `labels_`: les numéros de groupe des points de la matrice\n",
        "  d’observations.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bafd07d8",
      "metadata": {
        "id": "bafd07d8"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Quelles sont les valeurs par défaut des paramètres importants de DBSCAN dans scikit-learn ($ \\varepsilon $ et $ m $) ?\n",
        "\n",
        "Appliquons une classification automatique par DBSCAN sur notre jeu de\n",
        "données. Comme pour k-means, il est possible de réaliser cette étape en\n",
        "deux temps en appelant `fit()` puis en accédant à l’attribut\n",
        "`labels_`, ou de tout faire en une seule manipulation à l’aide de la\n",
        "méthode `fit_predict()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4828a896",
      "metadata": {
        "hide-output": false,
        "id": "4828a896"
      },
      "outputs": [],
      "source": [
        "predictions = db.fit_predict(data)\n",
        "# équivalent à\n",
        "# db.fit(data)\n",
        "# predictions = db.labels_\n",
        "\n",
        "# Affichage du nuage de points coloré par les prédictions\n",
        "plt.scatter(data[:,0], data[:,1], c=predictions)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9e556a3",
      "metadata": {
        "id": "d9e556a3"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Que constatez-vous ? Sur quel paramètre est-il vraisemblablement nécessaire de jouer pour améliorer ce résultat ?\n",
        "\n",
        "Pour raffiner notre analyse, nous allons appliquer l’heuristique de\n",
        "Schubert, qui exploite le graphe des $ k $-distances dans le nuage\n",
        "des observations. On considère pour l’instant que `min_samples` est\n",
        "fixé à sa valeur par défaut, c’est-à-dire 5. Nous devons donc tracer les\n",
        "graphe des 4-distances pour notre matrice d’observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c28e7a9",
      "metadata": {
        "hide-output": false,
        "id": "5c28e7a9"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=4).fit(data)\n",
        "distances, _ = nn.kneighbors(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b47591e",
      "metadata": {
        "id": "3b47591e"
      },
      "source": [
        "## Question :\n",
        "\n",
        "En vous aidant de la [documentation de NearestNeighbours dans scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors.kneighbors), expliquez ce que fait le code ci-dessus.\n",
        "\n",
        "Nous pouvons maintenant tracer le graphe des 4-distances. Pour ce faire,\n",
        "on ne conserve que la distance de chaque point à son quatrième voisin,\n",
        "puis on trie cette liste par ordre décroissant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecff501e",
      "metadata": {
        "hide-output": false,
        "id": "ecff501e"
      },
      "outputs": [],
      "source": [
        "distances_triees = np.sort(distances[:,-1])[::-1]\n",
        "plt.plot(distances_triees)\n",
        "plt.xlabel(\"Nombre de points\")\n",
        "plt.ylabel(\"$4$-distance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f07b76",
      "metadata": {
        "id": "59f07b76"
      },
      "source": [
        "## Question :\n",
        "\n",
        "À partir du graphe des 4-distances, déterminez la valeur de `eps` adaptée pour ce jeu de données en utilisant l’heuristique vue en cours. Appliquez de nouveau DBSCAN avec ces paramètres. Affichez le nuage de points obtenu."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705c5f62",
      "metadata": {
        "id": "705c5f62"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Combien obtenez vous de groupes ? À quoi correspondent les observations d’étiquette `-1` ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0dfd94b",
      "metadata": {
        "id": "a0dfd94b"
      },
      "source": [
        "## Classification avec DBSCAN des données « Iris »\n",
        "\n",
        "Le jeu de données Iris est est un grand classique de l’apprentissage\n",
        "statistique. Il comporte 150 observations de plantes selon quatre\n",
        "attributs :\n",
        "\n",
        "- longueur de la\n",
        "  [sépale](https://fr.wikipedia.org/wiki/S%C3%A9pale),  \n",
        "- largeur de la sépale,  \n",
        "- longueur de la pétale,  \n",
        "- largeur de la pétale.  \n",
        "\n",
        "\n",
        "Les observations appartiennent à l’une des trois classes, correspondant\n",
        "aux trois espèces d’iris: *Setosa*, *Versicolour* ou *Virginica*.\n",
        "\n",
        "Plus de détails peuvent se trouver dans la\n",
        "[documentation](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset).\n",
        "\n",
        "Iris est intégré à scikit-learn et est disponible depuis le sous-module\n",
        "`sklearn.datasets`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab0452f",
      "metadata": {
        "hide-output": false,
        "id": "5ab0452f"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "X, y = load_iris(return_X_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a61071fd",
      "metadata": {
        "id": "a61071fd"
      },
      "source": [
        "## Question\n",
        "\n",
        "Combien ce jeu de données contient-il d’observations?\n",
        "\n",
        "Afin de simuler la présence de données aberrantes, nous allons générer aléatoirement 20 points bruitées, tirées selon une loi uniforme entre les valeurs minimales et maximales de chaque colonne de la matrice d’observation :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d6c0f1",
      "metadata": {
        "hide-output": false,
        "id": "e6d6c0f1"
      },
      "outputs": [],
      "source": [
        "min_, max_ = X.min(axis=0), X.max(axis=0)\n",
        "noise = np.random.rand(20, 4) * (max_ - min_) + min_\n",
        "X = np.concatenate((X, noise))\n",
        "y = np.concatenate((y, -1 * np.ones(20, dtype=int)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4aa2fa4",
      "metadata": {
        "id": "b4aa2fa4"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Réalisez une analyse en composantes principales et visualisez le jeu de données Iris projeté selon ses deux premiers axes principaux."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e17ec4f",
      "metadata": {
        "id": "4e17ec4f"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Appliquez une classification automatique à l’aide de DBSCAN (travaillez sur les données en dimension 4, pas les données projetées !). Visualisez les groupes obtenus dans le plan principal. Comparez ce résultat au partitionnement obtenu à l’aide d’un *k-means*.\n",
        "\n",
        "Les points correpsondant à l’étiquette -1 sont ceux ayant été identifiés\n",
        "comme données aberrantes (*outliers*). Si la valeur de\n",
        "$ \\varepsilon $ a bien été choisie, les observations bruitées que\n",
        "nous avons injecté dans le jeu de données devraient ainsi avoir été\n",
        "isolées par DBSCAN."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14439d22",
      "metadata": {
        "id": "14439d22"
      },
      "source": [
        "## Question :\n",
        "\n",
        "À l’aide des fonctions de `sklearn.metrics`, calculez le taux de bonne détection des *outliers*. Jusqu’à quelle proportion de données bruitées le partitionnement obtenu par DBSCAN est-il robuste ?"
      ]
    }
  ],
  "metadata": {
    "date": 1727854216.6391044,
    "filename": "tpDBSCAN.rst",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python"
    },
    "title": "Travaux pratiques - DBSCAN",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}