{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/CHPS0704/blob/main/TP3/7_encore_du_Kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b756b066",
      "metadata": {
        "id": "b756b066"
      },
      "source": [
        "\n",
        "<a id='chap-tpkmeans'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edc1e99d",
      "metadata": {
        "id": "edc1e99d"
      },
      "source": [
        "# Travaux pratiques - K-means\n",
        "\n",
        "\n",
        "Références externes utiles :\n",
        "\n",
        "> - [Documentation NumPy](https://docs.scipy.org/doc/numpy/user/index.html)  \n",
        "- [Documentation SciPy](https://docs.scipy.org/doc/scipy/reference/)  \n",
        "- [Documentation MatPlotLib](http://matplotlib.org/)  \n",
        "- [Site scikit-learn](http://scikit-learn.org/stable/index.html)  \n",
        "- [Site langage python](https://www.python.org)  \n",
        "\n",
        "\n",
        "\n",
        "**L’objectif** de cette séance de TP est de présenter l’utilisation des fonctionnalités de scikit-learn concernant la classification automatique avec *k-means*, ainsi que de contribuer à une meilleure compréhension de cette méthode et de l’impact sur les résultats de la distribution des données ou de la technique d’initialisation (initialisation aléatoire ou *k-means++*). Pour cela, sont d’abord examinées des données générées de façon contrôlée et ensuite des données réelles vues en cours, sans ou avec un pré-traitement permettant de renforcer la séparation entre groupes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2c0fce0",
      "metadata": {
        "id": "a2c0fce0"
      },
      "source": [
        "## La classification automatique dans scikit-learn\n",
        "\n",
        "[Des méthodes de classification automatique variées](http://scikit-learn.org/stable/modules/clustering.html) sont disponibles dans scikit-learn. Parmi ces méthodes nous examinerons de plus près les K-moyennes (*K-means*) et ultérieurement la classification spectrale (*spectral clustering*).\n",
        "\n",
        "Pour chaque méthode, l’implémentation permet d’obtenir un « modèle » (par ex., un ensemble de *k* centres de groupes) à partir des données (sous forme de tableau de `n_samples x n_features` ainsi que, pour certaines méthodes, de matrice de similarités `n_samples x n_samples`) et ensuite d’obtenir le numéro de groupe (*cluster*) pour les données initiales ou pour de nouvelles données.\n",
        "\n",
        "La description de l’implémentation de la méthode des K-moyennes (*K-means*) se trouve dans [http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
        "\n",
        "Nous nous servirons également de l’indice de Rand ajusté, voir [https://scikit-learn.org/stable/modules/clustering.html#adjusted-rand-score](https://scikit-learn.org/stable/modules/clustering.html#adjusted-rand-score), pour évaluer la cohérence entre des classifications différentes d’un même ensemble de données. Pour d’autres méthodes permettant de comparer les résultats de différentes classifications voir [WW07], [VEB10]."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6c6baa",
      "metadata": {
        "id": "be6c6baa"
      },
      "source": [
        "## Classification avec K-means de données générées\n",
        "\n",
        "Démarrez par la génération de cinq groupes de 100 vecteurs chacun dans l’espace 3D, chacun suivant une loi normale (de moyenne nulle et de variance unitaire). Appliquez à chaque groupe une translation différente dans l’espace, générez les étiquettes de groupe, construisez l’ensemble total de données et mélangez ensuite les lignes de cet ensemble :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d0cf54",
      "metadata": {
        "hide-output": false,
        "id": "14d0cf54"
      },
      "outputs": [],
      "source": [
        "import numpy as np    # si pas encore fait\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# génération 100 points 3D suivant loi normale centrée\n",
        "# chaque groupe est translaté d'un vecteur [3,3,3]\n",
        "d1 = np.random.randn(100,3) + [3,3,3]\n",
        "d2 = np.random.randn(100,3) + [-3,-3,-3]\n",
        "d3 = np.random.randn(100,3) + [-3,3,3]\n",
        "d4 = np.random.randn(100,3) + [-3,-3,3]\n",
        "d5 = np.random.randn(100,3) + [3,3,-3]\n",
        "\n",
        "# génération des étiquettes de chaque groupe\n",
        "c1 = np.ones(100)\n",
        "c2 = 2 * np.ones(100)\n",
        "c3 = 3 * np.ones(100)\n",
        "c4 = 4 * np.ones(100)\n",
        "c5 = 5 * np.ones(100)\n",
        "\n",
        "# concaténation des données dans une matrice\n",
        "data = np.concatenate((d1,d2,d3,d4,d5))\n",
        "labels = np.concatenate((c1, c2, c3, c4, c5))\n",
        "print(data.shape)\n",
        "# permutation aléatoire des lignes de la matrice data\n",
        "data, labels = shuffle(data, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dff49fe",
      "metadata": {
        "id": "9dff49fe"
      },
      "source": [
        "Visualisez les groupes de départ :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f21ac62",
      "metadata": {
        "hide-output": false,
        "id": "9f21ac62"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "# La couleur des points dépend de leur étiquette (label)\n",
        "ax.scatter(data[:,0], data[:,1], data[:,2], c=labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d56d217",
      "metadata": {
        "id": "9d56d217"
      },
      "source": [
        "Appliquez la classification automatique avec *K-means*, d’abord avec un seul essai (une seule initialisation suivie d’une seule exécution de *K-means*, `n_init = 1`) utilisant la méthode d’initialisation `k-means++` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb48f44b",
      "metadata": {
        "hide-output": false,
        "id": "bb48f44b"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=5, n_init=1, init='k-means++').fit(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f5cfad8",
      "metadata": {
        "id": "1f5cfad8"
      },
      "source": [
        "Examinez les paramètres, les attributs et les méthodes de la classe `sklearn.cluster.KMeans` en suivant le lien indiqué plus haut.\n",
        "\n",
        "On peut obtenir les groupes prédits pour les données à l’aide de la méthode `predict(X)` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9acc94b",
      "metadata": {
        "hide-output": false,
        "id": "f9acc94b"
      },
      "outputs": [],
      "source": [
        "pred = kmeans.predict(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab5ca2b8",
      "metadata": {
        "id": "ab5ca2b8"
      },
      "source": [
        "Les groupes associés aux exemples d’apprentissage sont également stockés dans l’attribut `kmeans.labels_` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a150dc3e",
      "metadata": {
        "hide-output": false,
        "id": "a150dc3e"
      },
      "outputs": [],
      "source": [
        "print(kmeans.labels_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "564cb388",
      "metadata": {
        "id": "564cb388"
      },
      "source": [
        "Visualisez les résultats de cette classification :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3821c274",
      "metadata": {
        "hide-output": false,
        "id": "3821c274"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(data[:,0], data[:,1], data[:,2], c=pred)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cabc78aa",
      "metadata": {
        "id": "cabc78aa"
      },
      "source": [
        "Il est possible d’évaluer la cohérence entre les groupes de départ et le partitionnement trouvé par *K-means* en utilisant [l’indice de Rand ajusté](https://fr.wikipedia.org/wiki/Indice_de_Rand) (voir le cours et la documentation) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b27ede66",
      "metadata": {
        "hide-output": false,
        "id": "b27ede66"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "metrics.adjusted_rand_score(pred, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6310af04",
      "metadata": {
        "id": "6310af04"
      },
      "source": [
        "L’appel à `metrics.adjusted_rand_score()` compare le partitionnement obtenu par la classification automatique (étiquettes de groupe de `pred`) avec le partitionnement correspondant aux groupes définis au départ (étiquettes stockées dans `labels`).\n",
        "\n",
        "Appliquez maintenant la classification automatique avec *K-means* avec un seul essai (`n_init = 1`) utilisant la méthode d’initialisation `random` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097c65d2",
      "metadata": {
        "hide-output": false,
        "id": "097c65d2"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters=5, n_init=1, init='random').fit(data)\n",
        "metrics.adjusted_rand_score(kmeans.labels_, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c6f9d5",
      "metadata": {
        "id": "29c6f9d5"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Répétez plusieurs fois la classification avec chacune de ces deux méthodes d’initialisation et examinez à chaque fois la cohérence des groupes obtenus avec les groupes de départ. Que constatez-vous ? Expliquez."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "802f181d",
      "metadata": {
        "id": "802f181d"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Variez le nombre de groupes (`n_clusters`) et faites plusieurs essais pour chaque valeur du nombre de groupes. Examinez de nouveau la stabilité des résultats en utilisant l’indice de Rand ajusté. Expliquez ce que vous constatez."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e22dc4",
      "metadata": {
        "id": "a8e22dc4"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Variez le nombre de groupes (`n_clusters`) entre 2 et 20, tracez le graphique d’évolution de la valeur finale atteinte par le coût (l’inertie, voir [la documentation](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)) pour chacune des valeurs de `n_clusters`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c16b224",
      "metadata": {
        "hide-output": false,
        "id": "6c16b224"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "63717c6b",
      "metadata": {
        "id": "63717c6b"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Générez 500 données suivant une distribution **uniforme** dans $ [0, 1)^3 $ (données tridimensionnelles dans le cube unité). Appliquez sur ces données *K-means* avec `n_clusters=5` et initialisation aléatoire (`random`), et examinez la stabilité des résultats en utilisant l’indice de Rand. Appliquez sur ces mêmes données *K-means* avec toujours `n_clusters=5` mais une initialisation `k-means++`, examinez la stabilité des résultats. Attention, vous ne disposez plus de groupes définis au départ ; pour définir les groupes de référence, auxquels vous comparerez ceux issus des autres classifications, vous pouvez appliquer une première fois *K-means* avec `n_clusters=5, n_init=1, init='k-means++'`. Observez-vous des différences par rapport aux résultats obtenus sur les données générées au début de cette section (avec `np.random.randn`) ? Expliquez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51821763",
      "metadata": {
        "hide-output": false,
        "id": "51821763"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4c78f3e7",
      "metadata": {
        "id": "4c78f3e7"
      },
      "source": [
        "## Classification avec K-means des données « textures »\n",
        "\n",
        "Pour rappel, ces données correspondent à 5500 observations décrites par 40 variables. Chaque observation appartient à une des 11 classes de textures ; chaque classe est représentée par 500 observations. Les données sont issues de [https://www.elen.ucl.ac.be/neural-nets/Research/Projects/ELENA/databases/REAL/texture/](https://www.openml.org/search?type=data&sort=runs&id=40499&status=active). Nous appliquerons *K-means* à ces données, avec `n_clusters = 11`, et examinerons dans quelle mesure les groupes issus de la classification automatique se rapprochent des classes présentes.\n",
        "\n",
        "Si les données ne sont pas dans le répertoire de travail il est nécessaire de les chercher d’abord. En ligne de commande :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2f9bf86",
      "metadata": {
        "hide-output": false,
        "id": "b2f9bf86"
      },
      "outputs": [],
      "source": [
        "!wget -nc https://raw.githubusercontent.com/lsteffenel/CHPS0704/refs/heads/main/data/texture.dat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baf6f588",
      "metadata": {
        "id": "baf6f588"
      },
      "source": [
        "Mélangez les observations et appliquez *K-means* à ces données (attention, la dernière colonne contient les étiquettes de classe) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd214fc5",
      "metadata": {
        "hide-output": false,
        "id": "bd214fc5"
      },
      "outputs": [],
      "source": [
        "textures = np.loadtxt('texture.dat')\n",
        "np.random.shuffle(textures)\n",
        "kmeans = KMeans(n_clusters=11).fit(textures[:,:40])\n",
        "metrics.adjusted_rand_score(kmeans.labels_, textures[:,40])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5041e4a7",
      "metadata": {
        "id": "5041e4a7"
      },
      "source": [
        "On constate que les groupes issus de la classification automatique ne donnent que peu d’indications sur les classes présentes dans ces données."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d04bd90",
      "metadata": {
        "id": "6d04bd90"
      },
      "source": [
        "## Question :\n",
        "\n",
        "Essayez de réduire le nombre de variables (par simple observation, PCA, etc.). Exécutez de nouveau *K-means* avec `n_clusters = 11` aux données projetées dans l’espace discriminant. Que constatez-vous ? Visualisez les résultats."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fqq0--ZdE63i"
      },
      "id": "Fqq0--ZdE63i",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "date": 1727854216.7256148,
    "filename": "tpKmeans.rst",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python"
    },
    "title": "Travaux pratiques - K-means",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}