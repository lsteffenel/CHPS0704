{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNwYQGSnJGrKV3Tiho09++m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/CHPS0704/blob/main/TP5/3-Conso_electrique_LSTM_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilisation de LSTM et GRU pour modéliser la consommation éléctrique d'une ville\n",
        "\n",
        "On va utiliser le dataset 'NI_hourly.csv'"
      ],
      "metadata": {
        "id": "FCIJxMos1GeI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5fBnx8qqDQE"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PARAMETERS\n",
        "\n",
        "# length of sliding window\n",
        "features = 240\n",
        "# length of test dataset\n",
        "test_ts_len = 300\n",
        "# size of LSTM hidden state\n",
        "lstm_hidden_size = 24\n",
        "# Optimizer learning rate\n",
        "learning_rate = 0.02\n",
        "\n",
        "training_epochs = 100\n",
        "\n"
      ],
      "metadata": {
        "id": "d1AOUSc2rKvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_size,\n",
        "                 in_size = 1,\n",
        "                 out_size = 1):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size = in_size,\n",
        "            hidden_size = hidden_size,\n",
        "            batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, x, h = None):\n",
        "        out, h = self.lstm(x, h)\n",
        "        last_hidden_states = out[:, -1]\n",
        "        out = self.fc(last_hidden_states)\n",
        "        return out, h"
      ],
      "metadata": {
        "id": "YqaeHocVsxjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window(ts, features):\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for i in range(features + 1, len(ts) + 1):\n",
        "        X.append(ts[i - (features + 1):i - 1])\n",
        "        Y.append([ts[i - 1]])\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def get_ni_timeseries():\n",
        "    df = pd.read_csv('NI_hourly.csv')\n",
        "    ts = df['NI_MW'].astype(int).values.reshape(-1, 1)[-3000:]\n",
        "    return ts\n",
        "\n",
        "\n",
        "def get_training_datasets(ts, features, test_len):\n",
        "    X, Y = sliding_window(ts, features)\n",
        "\n",
        "    X_train, Y_train, X_test, Y_test = X[0:-test_len],\\\n",
        "                                       Y[0:-test_len],\\\n",
        "                                       X[-test_len:],\\\n",
        "                                       Y[-test_len:]\n",
        "\n",
        "    train_len = round(len(ts) * 0.7)\n",
        "\n",
        "    X_train, X_val, Y_train, Y_val = X_train[0:train_len],\\\n",
        "                                     X_train[train_len:],\\\n",
        "                                     Y_train[0:train_len],\\\n",
        "                                     Y_train[train_len:]\n",
        "\n",
        "    x_train = torch.tensor(data = X_train).float()\n",
        "    y_train = torch.tensor(data = Y_train).float()\n",
        "\n",
        "    x_val = torch.tensor(data = X_val).float()\n",
        "    y_val = torch.tensor(data = Y_val).float()\n",
        "\n",
        "    x_test = torch.tensor(data = X_test).float()\n",
        "    y_test = torch.tensor(data = Y_test).float()\n",
        "\n",
        "    return x_train, x_val, x_test,\\\n",
        "           y_train.squeeze(1), y_val.squeeze(1), y_test.squeeze(1)"
      ],
      "metadata": {
        "id": "ey7PB7Q2sTLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing datasets for Training\n",
        "\n",
        "ts = get_ni_timeseries()\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_ts = scaler.fit_transform(ts)\n",
        "x_train, x_val, x_test, y_train, y_val, y_test =\\\n",
        "    get_training_datasets(scaled_ts, features, test_ts_len)\n",
        "\n",
        "# Initializing the model\n",
        "model = LSTM(hidden_size = lstm_hidden_size)\n",
        "model.train()\n",
        "\n",
        "# Training\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\n",
        "mse_loss = torch.nn.MSELoss()\n",
        "\n",
        "best_model = None\n",
        "min_val_loss = sys.maxsize\n",
        "\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "for t in range(training_epochs):\n",
        "\n",
        "    prediction, _ = model(x_train)\n",
        "    loss = mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    val_prediction, _ = model(x_val)\n",
        "    val_loss = mse_loss(val_prediction, y_val)\n",
        "\n",
        "    training_loss.append(loss.item())\n",
        "    validation_loss.append(val_loss.item())\n",
        "\n",
        "    if val_loss.item() < min_val_loss:\n",
        "        best_model = copy.deepcopy(model)\n",
        "        min_val_loss = val_loss.item()\n",
        "\n",
        "    if t % 10 == 0:\n",
        "        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n",
        "              f'val: - {round(val_loss.item(), 4)}')\n",
        "\n",
        "best_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    _, h_list = best_model(x_val)\n",
        "    # warm hidden and cell state\n",
        "    h = tuple([(h[-1, -1, :]).unsqueeze(-2).unsqueeze(-2)\n",
        "               for h in h_list])\n",
        "\n",
        "    predicted = []\n",
        "    for test_seq in x_test.tolist():\n",
        "        x = torch.Tensor(data = [test_seq])\n",
        "        # passing hidden state and cell through each iteration\n",
        "        y, h = best_model(x, h)\n",
        "        unscaled = scaler.inverse_transform(\n",
        "            np.array(y.item()).reshape(-1, 1))[0][0]\n",
        "        predicted.append(unscaled)\n",
        "\n",
        "real = scaler.inverse_transform(y_test.tolist())\n",
        "\n"
      ],
      "metadata": {
        "id": "Kj9IqrQDsjUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Test dataset\")\n",
        "plt.plot(real, label = 'real')\n",
        "plt.plot(predicted, label = 'predicted')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.title('Training')\n",
        "plt.yscale('log')\n",
        "plt.plot(training_loss, label = 'training')\n",
        "plt.plot(validation_loss, label = 'validation')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1_bY_S9fsr9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Challenge\n",
        "\n",
        "Maintenant, comparez la performance de LSTM avec GRU et un RNN simple, à l'aide des classes suivantes :"
      ],
      "metadata": {
        "id": "kOZq2_EWvPkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_size,\n",
        "                 in_size = 1,\n",
        "                 out_size = 1):\n",
        "        super(GRU, self).__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size = in_size,\n",
        "            hidden_size = hidden_size,\n",
        "            batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, x, h = None):\n",
        "        out, _ = self.gru(x, h)\n",
        "        last_hidden_states = out[:, -1]\n",
        "        out = self.fc(last_hidden_states)\n",
        "        return out, last_hidden_states\n",
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_size,\n",
        "                 in_size = 1,\n",
        "                 out_size = 1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size = in_size,\n",
        "            hidden_size = hidden_size,\n",
        "            batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, x, h = None):\n",
        "        out, _ = self.rnn(x, h)\n",
        "        last_hidden_states = out[:, -1]\n",
        "        out = self.fc(last_hidden_states)\n",
        "        return out, last_hidden_states"
      ],
      "metadata": {
        "id": "G2v1LgbAvPJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entraîner vos modèles puis comparer leurs **loss** et plottez leurs prédictions"
      ],
      "metadata": {
        "id": "N9iLSK5FveBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the model\n",
        "\n",
        "\n",
        "### TODO\n"
      ],
      "metadata": {
        "id": "n3rPXrOy0Sds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training\n",
        "\n",
        "## TODO"
      ],
      "metadata": {
        "id": "vHk7TaVI0LSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ce paragraphe est \"cadeau\" car il y a une petite différence sur les dimensions entre LSTM et GRU ;)"
      ],
      "metadata": {
        "id": "RgaixFS_0ma1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    _, h_list = best_model(x_val)\n",
        "    # warm hidden and cell state\n",
        "    h = (h_list[-1, :]).unsqueeze(-2)\n",
        "\n",
        "    predicted = []\n",
        "    for test_seq in x_test.tolist():\n",
        "        x = torch.Tensor(data = [test_seq])\n",
        "        # passing hidden state and cell through each iteration\n",
        "        y, h = best_model(x, h.unsqueeze(-2))\n",
        "        unscaled = scaler.inverse_transform(\n",
        "            np.array(y.item()).reshape(-1, 1))[0][0]\n",
        "        predicted.append(unscaled)\n",
        "\n",
        "real = scaler.inverse_transform(y_test.tolist())"
      ],
      "metadata": {
        "id": "xazs3tfDyJqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## PLOT"
      ],
      "metadata": {
        "id": "FiqwUN--v4A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G92iCivOv43x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}